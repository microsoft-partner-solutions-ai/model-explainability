{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import json \n",
        "\n",
        "from azureml.core import Workspace\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.interpret.scoring.scoring_explainer import TreeScoringExplainer, LinearScoringExplainer, ScoringExplainer, save\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "from azureml.train.automl.runtime.automl_explain_utilities import automl_setup_model_explanations\n",
        "from azureml.interpret import MimicWrapper\n",
        "from automl.client.core.common.constants import MODEL_PATH\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1616174628913
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate and pickle an Explainer Object"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# get workspace from config\n",
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1616164329376
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to classifier experiment and automl run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = ws.experiments[<EXPERIMENT NAME>]\n",
        "automl_run = AutoMLRun(experiment, run_id = <RUN ID>)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616164331884
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run = automl_run.get_best_child()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616164336746
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the model locally. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run.download_file(name=MODEL_PATH, output_file_path='Models/model.pkl')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1616110005262
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fitted_model = joblib.load('Models/model.pkl')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1616174843329
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load dataset as Pandas Dataframe\n",
        "* Run 1st cell to read data from .csv (faster)\n",
        "* Run 2nd cell to read data from AML Dataset, doesn't require an additional csv"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment and run this cell to read data from file - faster than reading from Dataset in AML\n",
        "\n",
        "# df = pd.read_csv('data/data.csv',index_col=0)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1616164672265
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to read data from Dataset (takes longer than above cell, but doesn't require extra data.csv file)\n",
        "\n",
        "dataset = Dataset.get_by_name(ws, name=<DATA SET NAME>, version=\"latest\")\n",
        "df = dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1616098445837
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the labeled column to get the training set.\n",
        "target = '<TARGET COLUMN NAME>'\n",
        "X = df.drop(columns=[target])\n",
        "y = df[target]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1616098445998
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split your data and setup the explainer"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train & test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=0)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1616164731648
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the class for explaining the AutoML models\n",
        "automl_explainer_setup_obj = automl_setup_model_explanations(fitted_model, \n",
        "                                                             task='classification',\n",
        "                                                             X=X_train,\n",
        "                                                             X_test=X_test,\n",
        "                                                             y=y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616110098042
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Mimic Explainer\n",
        "explainer = MimicWrapper(ws, automl_explainer_setup_obj.automl_estimator, \n",
        "                         explainable_model=automl_explainer_setup_obj.surrogate_model,\n",
        "                         init_dataset=automl_explainer_setup_obj.X_transform,\n",
        "                         run=best_run,\n",
        "                         features=automl_explainer_setup_obj.engineered_feature_names,\n",
        "                         feature_maps=[automl_explainer_setup_obj.feature_map],\n",
        "                         classes=automl_explainer_setup_obj.classes)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616110155919
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Mimic Explainer to compute and visualize the global raw feature importance\n",
        "raw_explanations = explainer.explain(['local', 'global'], get_raw=True,\n",
        "                                     raw_feature_names=automl_explainer_setup_obj.raw_feature_names,\n",
        "                                     eval_dataset=automl_explainer_setup_obj.X_test_transform)\n",
        "print(raw_explanations.get_feature_importance_dict())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616105210507
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test local explanations"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Run 1st cell to initialize scoring explainer - use TreeScoringExplainer if tree-based model\n",
        "* Run 2nd cell to load pickled scoring explainer if already saved"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a Linear Scoring Explainer for linear models\n",
        "scoring_explainer = LinearScoringExplainer(explainer, initialization_examples=automl_explainer_setup_obj.X_test_transform, feature_maps=[automl_explainer_setup_obj.feature_map])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616110168234
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment out this cell if you have a pickled scoring explainer already saved\n",
        "\n",
        "# scoring_explainer = joblib.load('models/scoring_explainer.pkl')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616174793415
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To test you can use a dummy input sample or pull one from the test data set. If you're making a dummy input sample it should look something like this\n",
        "input_sample = pd.DataFrame([\n",
        "    {\n",
        "        \"<FEATURENAME1>\": \"VALUE1:\",\n",
        "        \"<FEATURENAME2>\": \"VALUE2\"\n",
        "    }\n",
        "])\n",
        "input_sample"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616174799092
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup for inferencing explanations\n",
        "data = input_sample # Can change value to X_test[:5]\n",
        "automl_explainer_setup_obj = automl_setup_model_explanations(fitted_model,X_test=data, task='classification')\n",
        "raw_local_importance_values = scoring_explainer.explain(automl_explainer_setup_obj.X_test_transform, get_raw=True)\n",
        "print(raw_local_importance_values)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616174848941
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get explanations with feature names, reverse sorted by importance score\n",
        "\n",
        "num_records = data.shape[0]\n",
        "explanations = []\n",
        "for i in range(num_records):\n",
        "    exp_dict = dict(zip(automl_explainer_setup_obj.raw_feature_names,raw_local_importance_values[i]))\n",
        "    sorted_exp_dict = dict(sorted(exp_dict.items(), key=lambda item: item[1], reverse=True))\n",
        "    explanations.append(sorted_exp_dict)\n",
        "\n",
        "print(explanations)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616116287508
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get explanations with feature names, formatted as list of json objects\n",
        "\n",
        "num_records = data.shape[0]\n",
        "num_features = len(automl_explainer_setup_obj.raw_feature_names)\n",
        "explanations_all = []\n",
        "for i in range(num_records):\n",
        "    explanations = []\n",
        "    for j in range(num_features):\n",
        "        exp_dict = {automl_explainer_setup_obj.raw_feature_names[j]: raw_local_importance_values[i][j]}\n",
        "        explanations.append(exp_dict)\n",
        "    explanations_all.append(explanations)\n",
        "print(explanations_all)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616174853272
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pickle explainer and upload to be registered and accessed in scoring script\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Pickle scoring explainer locally\n",
        "save(scoring_explainer, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616110202474
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the scoring explainer to the automl run\n",
        "best_run.upload_file('outputs/scoring_explainer-1.pkl', 'scoring_explainer.pkl') "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616110263806
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scoring_explainer_model = best_run.register_model(model_name='scoring_explainer', model_path='outputs/scoring_explainer-1.pkl')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616110278616
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
      "display_name": "Python 3.9.0 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "metadata": {
      "interpreter": {
        "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}